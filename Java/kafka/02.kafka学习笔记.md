# kafka学习笔记

---

## 1.kafka特点
* 高吞吐量，分布式，可复制的发布订阅消息系统
* 分布式:
	* producer,broker,consumer可部署多台机器上
	* 使用zookeeper进行分布式协调
* 高性能
	* 端到端压缩
	* 批量发送，异步发送
	* 顺序读写
	* 使用sero copy技术
* 功能简单实用
	* 支持持久化
	* 消费者从broker拉取数据
	* 支持分区，可并行消费
	* 消费的消费状态由消费者维护
	* 支持多个副本，自动切换leader

## 2.Kafka相关概念
* broker:一个服务器实例
* topic:一个消息流
* partition：分区，每个topic可以按特定的分区逻辑分区，类似mysql的分表,分区是在生产端进行
* producer：消息生产者
* consumer：消息消费者
* consumer group:消费者组，相同groupid的consumer组成一个组
* offset：一条消息在消息流中的偏移

* 消息的生产和消费
	* 分区在producer端进行
	* 一个分区只会由组内的一个consumer消费，自动分配
	* offset由consumer端维护
	* 只能保证一个分区内的数据是有序的
	* 减少资源分配的粒度，充分利用资源
	* 分区是leader选举的单位
	
	![](http://i.imgur.com/YzQSJ1Z.png)

## 3.kafka负载均衡的原理
#### 3.1 负载均衡的两种策略
* range
	* 消费端配置使用range做负载均衡
		> partition.assignment.strategy=range
	* range是kafka默认并推荐的一个配置，特点是每个topic的分区独立分配
	* consumer中可以建多个线程
	* kafka的分区是以线程为粒度进行分配的
	* 分区按数字排序，线程按字典排序
	* partition_per_thread=分区数量/线程数量
	* 若整除，每个线程依次分配partition_per_thread个分区
	* 若不整除，低位的几个thread会多消费分区
	* 若分区数少于线程数，会有线程空闲
	* kafka保证每个分区被一个线程消费，不会有重复消费
	* 示意图
	  ![](http://i.imgur.com/PFNYiQf.png)
* round-robin
	* 消费端配置使用round-robin
		> partition.assignment.strategy=round-robin
	* 把所有topic的所有分区循环分配到所有线程上
	* 使用有限制
		* 每个topic在每个consumer中线程数量必须相同
		* 每个consumer消费的topic必须相同
* kafka自动的负载均衡策略
	* 若consumer端有线程挂掉,kafka会自动进行重新分配

## 4.kafka主从
> 主要目的：提供分区容错的能力

#### 4.1 分配的原则
* 分布要均匀

#### 4.1 分区及副本的配置逻辑
* 对于第n个副本，先随机取一个broker放分区0，然后顺序放其他分区
* 示意图
  ![](http://i.imgur.com/p3Hr2mM.png)

  * 先为leader按顺序分配存到每个broker上
  * 然后依次逻辑分配分区1
  * 在分配分区2
  * 顺序如图中框选
* 查看topic分配
	> ./bin/kafka-topics.sh --describe --zookeeper localhost:2181 -topic testkafka
	
	![](http://i.imgur.com/NxOV2f4.png)
	
* 主从一些术语
	* leader：负责读写
	* replicas：所有的副本，只有当消息被所有的副本加入到日志中时，才算是“commited”，只有commited的消息才会发送给consumer
	* Isr：replicas中所有的in-sync的节点
	* in-sync：
		* 节点必须可以维护和zookeeper的连接，zookeeper通过心跳机制检查每个节点的连接
		* 如果节点是个follower，必须能及时的同步leader的写操作，延迟不能太久
		* replica.lag.max.messages，落后的消息数量
		* replica.lag.time.ms，卡住的时间

## 5.kafka持久化

#### 5.1 持久化的消息格式
![](http://i.imgur.com/fIF4Y6g.png)

#### 5.2 文件
![](http://i.imgur.com/bOwV02n.png)

* 数据文件目录下按照topicName-n来划分,n表示分区的编号
* 在每个消息的分区内，文件名是消息的首offset，文件分log和index，分别是数据文件和索引文件
  
  ![](http://i.imgur.com/e5BNbrh.png)

* 本地存放数据时根据offset进行分段存储,segment
  
#### 5.3 过期数据的清理
* 直接删除，超时和超限，kafka的默认策略
	* 超时，超过指定的时间后删除，配置：
		> log.retention.hours=24
	* 超限，超过指定大小后删除旧消息，配置：
		> log.retention.bytes=102400
* 压缩，特定的业务场景下有意义
	* 全局配置，log.cleaner.enable=true
	* 在特定的topic上：log.cleanup.policy=compact
	* 保留每个key最后一个版本的消息
	* 若最后一个版本消息内容为空，这个key被删除
	
#### 5.4 使用持久化为何速度依然快？磁盘页缓存
* 硬盘的顺序读写比内存的随机读写要快
* 硬盘的主要性能消耗是寻道和旋转延时，真正用于读写数据的时间其实很少，使用顺序读写避免了过多的寻道和旋转延时
* kafka将文件写到内存的页缓存，然后按照定制的策略flush到硬盘.kafka不推荐修改默认的flush策略
* 关于flush策略的几条配置
	* log.flush.interval.messages 
	* log.flush.interval.ms
	* log.flush.scheduler.interval.ms
* jvm使用内存的一个页缓存来操作数据
* kafka使用操作系统默认的flush策略

* kafka使用的顺序读写保证速度的快

#### 5.5 zero copy
* zero copy，linux系统内核提供的一门技术
* 主要用于数据从硬盘发送到网卡阶段
* 不需要往应用内存中读，从内核直接读取并发送到网卡上
* java.nio.channel.FileChannel transferTo()

* 传统读数据需要经历内核态用户态，Linux为保证数据的安全在内核态还有很多的校验，切换很耗时

## 6.生产者消费者模型

#### 6.1 消费者模型
* 分区消费模型
	* 分区消费模型架构图
	![](http://i.imgur.com/KlnbMek.jpg)
	
	* 分区消费模型伪代码
	![](http://i.imgur.com/VYIrQ0e.jpg)

* 组(group)消费模型
	* 组消费模型架构图
	![](http://i.imgur.com/kEABCiH.png)

	* 组消费伪代码
	![](http://i.imgur.com/fJH9EmS.png)

* 两种模型对比
	* 分区消费模型更加灵活,但是需要自己处理各种异常情况，需要自己管理offset(实现消息传递的其他语义)
	* 组消费模型更加简单，但是不灵活，不需要自己处理异常情况，不需要自己管理offset.只能实现kafka默认的最少一次消息传递语义

#### 6.2 high level consumer
* 特点
	* offset在zookeeper中维护，重启可不间断的消费
	* offset提交频率可配置
		* auto.commit.enable
		* auto.commit.interval.ms
	* 每个consumer内部可启动多个线程
	* 自动负载均衡，不关心细节
	* 若consumer变动则自动reblance
	* 自动感知leader变更并切换
* 使用场景：比较注重性能和扩展，而不是事务
* 事务一致性的三个级别
	* 最多一次，不会重复消费
	* 最少一次，不会漏掉消息
	* 只有一次，不会重复也不会漏掉

#### 6.3 simple consumer api
* 特点：
	* 自己维护要消费的topic，分区，offset
	* 没有自动的负载均衡
	* 可回退到某个旧的offset消费
	* 连接集群中的一个broker可获取所有metadata
* 使用场景
	* 对事务一致性要求较高
	* 希望自己维护offset
	* 消费老的消息或部分消息(非顺序消息)

#### 6.4 生产者模型
* 特点:
	* 直连broker
	* 可批量发送，可异步发送
	* 可指定分区函数
	* 可指定broker的应答级别
#### 6.5 scala api for producer

#### 6.6 java api for producer
* 特点
	* 针对java提供的api，对于使用Java语言的调用更加友好
	* 线程安全，多个线程共享一个实例效率更高
	* 异步发送，send()将消息放到buffer后立马返回，由后台io线程负责将消息序列化和压缩后发送到broker集群
	* 利用分区函数进行分区
	* 自动重试
* 重要参数详解
	* batch.size : 打包发送消息字节数，大于这个值的消息直接发送
	* buffer.memory : 缓存的最大值
	* linger.ms : 在producer端负载不高的情况下可能需要较长时间达到buffer.size,增加发送的次数，此参数指定缓存填不满时的等待时间，类似TCP的Nagle算法
	* block.on.buffer.full : 缓存用光时的处理方式
		* true,阻塞直到有可用的空间
		* false，抛出BufferExhaustedException异常
	* retries: 重试次数，0禁止重试